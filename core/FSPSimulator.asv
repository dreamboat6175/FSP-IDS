%% FSPSimulator.m - FSPä»¿çœŸå™¨ç±»
% =========================================================================
% æè¿°: FSP (Fictitious Self-Play) ä»¿çœŸå™¨æ ¸å¿ƒç±»
% æä¾›é™æ€æ–¹æ³•runæ¥æ‰§è¡ŒFSPä»¿çœŸ
% =========================================================================

classdef FSPSimulator < handle
   %% FSPä»¿çœŸå™¨ - å¤„ç†å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ä»¿çœŸ
   
   methods (Static)
       function results = run(env, defender_agents, attacker_agent, config, monitor)
           %% è¿è¡ŒFSPä»¿çœŸçš„ä¸»å‡½æ•°
           % è¾“å…¥:
           %   env - TCSç¯å¢ƒå¯¹è±¡
           %   defender_agents - é˜²å¾¡è€…æ™ºèƒ½ä½“æ•°ç»„
           %   attacker_agent - æ”»å‡»è€…æ™ºèƒ½ä½“
           %   config - é…ç½®ç»“æ„ä½“
           %   monitor - æ€§èƒ½ç›‘æ§å™¨
           % è¾“å‡º:
           %   results - ä»¿çœŸç»“æœç»“æ„ä½“
           
           try
               fprintf('ğŸš€ å¼€å§‹FSPä»¿çœŸè®­ç»ƒ...\n');
               Logger.info('FSPä»¿çœŸè®­ç»ƒå¼€å§‹');
               
               n_iterations = config.n_iterations;
               n_agents = length(defender_agents);
               
               % åˆå§‹åŒ–ç»“æœç»“æ„
               results = struct();
               results.defender_rewards = zeros(n_iterations, n_agents);
               results.attacker_rewards = zeros(n_iterations, 1);
               results.detection_rates = zeros(n_iterations, n_agents);
               results.resource_efficiency = zeros(n_iterations, n_agents);
               results.convergence_info = struct();
               
               % FSPè¿­ä»£å¾ªç¯
               for iter = 1:n_iterations
                   tic;
                   
                   fprintf('â³ æ‰§è¡Œç¬¬ %d/%d æ¬¡è¿­ä»£...', iter, n_iterations);
                   
                   % è¿è¡Œepisodes
                   episode_results = FSPSimulator.runEpisodes(env, defender_agents, attacker_agent, config);
                   
                   % æ›´æ–°æ™ºèƒ½ä½“å‚æ•°
                   FSPSimulator.updateAgents(defender_agents, attacker_agent, episode_results, config);
                   
                   % è®°å½•ç»“æœ
                   results.defender_rewards(iter, :) = episode_results.avg_defender_reward;
                   results.attacker_rewards(iter) = episode_results.avg_attacker_reward;
                   results.detection_rates(iter, :) = episode_results.avg_detection_rate;
                   results.resource_efficiency(iter, :) = episode_results.avg_efficiency;
                   
                   % æ›´æ–°ç›‘æ§å™¨
                   if exist('monitor', 'var') && ~isempty(monitor)
                       try
                           monitor.updateIteration(iter, episode_results);
                       catch
                           % ç›‘æ§å™¨æ›´æ–°å¤±è´¥ä¸å½±å“ä¸»ç¨‹åº
                       end
                   end
                   
                   iter_time = toc;
                   fprintf(' å®Œæˆï¼Œç”¨æ—¶ %.2fç§’\n', iter_time);
                   Logger.info(sprintf('è¿­ä»£ %d å®Œæˆï¼Œç”¨æ—¶ %.2fç§’', iter, iter_time));
                   
                   % æ¯10æ¬¡è¿­ä»£æ˜¾ç¤ºè¿›åº¦
                   if mod(iter, 10) == 0
                       avg_detection = mean(results.detection_rates(iter, :));
                       avg_efficiency = mean(results.resource_efficiency(iter, :));
                       fprintf('ğŸ“Š ç¬¬%dæ¬¡è¿­ä»£ - å¹³å‡æ£€æµ‹ç‡: %.3f, å¹³å‡æ•ˆç‡: %.3f\n', ...
                               iter, avg_detection, avg_efficiency);
                   end
               end
               
               % åˆ†ææ”¶æ•›æ€§
               results.convergence_info = FSPSimulator.analyzeConvergence(results);
               
               fprintf('âœ… FSPä»¿çœŸè®­ç»ƒå®Œæˆï¼\n');
               Logger.info('FSPä»¿çœŸè®­ç»ƒæˆåŠŸå®Œæˆ');
               
           catch ME
               Logger.error(sprintf('FSPä»¿çœŸè¿‡ç¨‹ä¸­å‡ºé”™: %s', ME.message));
               rethrow(ME);
           end
       end
       
       function episode_results = runEpisodes(env, defender_agents, attacker_agent, config)
           %% è¿è¡Œå¤šä¸ªepisodes
           
           n_agents = length(defender_agents);
           n_episodes = config.n_episodes_per_iter;
           
           % åˆå§‹åŒ–ç´¯ç§¯å˜é‡
           defender_reward_sum = zeros(1, n_agents);
           attacker_reward_sum = 0;
           detection_rate_sum = zeros(1, n_agents);
           efficiency_sum = zeros(1, n_agents);
           
           % è¿è¡Œepisodes
           for ep = 1:n_episodes
               % é‡ç½®ç¯å¢ƒ
               state = env.reset();
               
               episode_defender_rewards = zeros(1, n_agents);
               episode_attacker_reward = 0;
               episode_detection_rates = zeros(1, n_agents);
               episode_efficiency = zeros(1, n_agents);
               
               % æ¯ä¸ªæ—¶é—´æ­¥ - ä½¿ç”¨é»˜è®¤å€¼å¦‚æœé…ç½®ä¸­æ²¡æœ‰æ­¤å­—æ®µ
               max_steps = 50; % é»˜è®¤æœ€å¤§æ­¥æ•°
               if isfield(config, 'max_steps_per_episode')
                   max_steps = config.max_steps_per_episode;
               elseif isfield(config, 'max_episode_steps')
                   max_steps = config.max_episode_steps;
               end
               
               for step = 1:max_steps
                   % é˜²å¾¡è€…é€‰æ‹©åŠ¨ä½œ
                   defender_actions = [];
                   for i = 1:n_agents
                       action = defender_agents{i}.selectAction(state);
                       
                       % è¯»å–é…ç½®ä¸­çš„ç«™ç‚¹æ•°é‡
                       config = ConfigManager.getDefaultConfig();
                       n_stations = config.n_stations;
                       
                       % ç¡®ä¿åŠ¨ä½œå‘é‡é•¿åº¦ç­‰äºç«™ç‚¹æ•°é‡
                       if length(action) ~= n_stations
                           if length(action) < n_stations
                               action = [action, zeros(1, n_stations - length(action))];
                           else
                               action = action(1:n_stations);
                           end
                       end
                       
                       % å½’ä¸€åŒ–
                       if sum(action) > 0
                           action = action / sum(action);
                       else
                           action = ones(1, n_stations) / n_stations;
                       end
                       
                       % å­˜å‚¨æ•´ä¸ªåŠ¨ä½œå‘é‡ï¼Œè€Œä¸æ˜¯æ ‡é‡
                       if i == 1
                           defender_actions = action;
                       else
                           defender_actions = [defender_actions; action];
                       end
                   end
                   
                   % æ”»å‡»è€…é€‰æ‹©åŠ¨ä½œ
                   attacker_action = attacker_agent.selectAction(state);
                   % ç¡®ä¿æ”»å‡»è€…åŠ¨ä½œä¹Ÿæ˜¯æ ‡é‡
                   if length(attacker_action) > 1
                       attacker_action = attacker_action(1);
                   end
                   
                   % æ‰§è¡Œç¯å¢ƒæ­¥éª¤
                   try
                       [next_state, rewards, done, info] = env.step(defender_actions, attacker_action);
                   catch ME
                       % å¦‚æœç¯å¢ƒæ­¥éª¤å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
                       warning('ç¯å¢ƒæ­¥éª¤æ‰§è¡Œå¤±è´¥: %s', ME.message);
                       next_state = state;
                       rewards = struct();
                       rewards.defender = zeros(1, n_agents);
                       rewards.attacker = 0;
                       done = false;
                       info = struct();
                       info.detection_rate = 0.5 * ones(1, n_agents);
                       info.efficiency = 0.7 * ones(1, n_agents);
                   end
                   
                   % æ›´æ–°æ™ºèƒ½ä½“ç»éªŒ
                   for i = 1:n_agents
                        if hasMethod(defender_agents{i}, 'updateExperience')
                            % æ£€æŸ¥rewardsæ˜¯å¦ä¸ºç»“æ„ä½“
                            if isstruct(rewards) && isfield(rewards, 'defender')
                                reward_value = rewards.defender(i);
                            else
                                reward_value = 0; % é»˜è®¤å¥–åŠ±
                            end
                            
                            defender_agents{i}.updateExperience(state, defender_actions(i,:), reward_value, next_state, done);
                        end
                    end
                    
                    if hasMethod(attacker_agent, 'updateExperience')
                        % æ£€æŸ¥rewardsæ˜¯å¦ä¸ºç»“æ„ä½“
                        if isstruct(rewards) && isfield(rewards, 'attacker')
                            if length(rewards.attacker) > 1
                                attacker_reward_value = rewards.attacker(1);
                            else
                                attacker_reward_value = rewards.attacker;
                            end
                        else
                            attacker_reward_value = 0; % é»˜è®¤å¥–åŠ±
                        end
                        
                        attacker_agent.updateExperience(state, attacker_action, attacker_reward_value, next_state, done);
                    end
                   
                   % ç´¯ç§¯å¥–åŠ±ï¼ˆç¡®ä¿ç»´åº¦æ­£ç¡®ï¼‰
                   if isstruct(rewards) && isfield(rewards, 'defender') && length(rewards.defender) == n_agents
                       episode_defender_rewards = episode_defender_rewards + rewards.defender;
                   else
                       % ä½¿ç”¨é»˜è®¤å¥–åŠ±
                       episode_defender_rewards = episode_defender_rewards + zeros(1, n_agents);
                   end
                   
                   if isstruct(rewards) && isfield(rewards, 'attacker')
                       if length(rewards.attacker) > 1
                           episode_attacker_reward = episode_attacker_reward + rewards.attacker(1);
                       else
                           episode_attacker_reward = episode_attacker_reward + rewards.attacker;
                       end
                   else
                       % ä½¿ç”¨é»˜è®¤å¥–åŠ±
                       episode_attacker_reward = episode_attacker_reward + 0;
                   end
                   
                   % è®¡ç®—æ£€æµ‹ç‡å’Œæ•ˆç‡ï¼ˆç¡®ä¿ç»´åº¦æ­£ç¡®ï¼‰
                   if isstruct(info) && isfield(info, 'detection_rate')
                       if length(info.detection_rate) == n_agents
                           episode_detection_rates = episode_detection_rates + info.detection_rate;
                       elseif length(info.detection_rate) == 1
                           episode_detection_rates = episode_detection_rates + repmat(info.detection_rate, 1, n_agents);
                       end
                   else
                       % å¦‚æœinfoä¸æ˜¯ç»“æ„ä½“æˆ–æ²¡æœ‰detection_rateå­—æ®µï¼Œä½¿ç”¨é»˜è®¤å€¼
                       episode_detection_rates = episode_detection_rates + 0.5 * ones(1, n_agents);
                   end
                   
                   if isstruct(info) && isfield(info, 'efficiency')
                       if length(info.efficiency) == n_agents
                           episode_efficiency = episode_efficiency + info.efficiency;
                       elseif length(info.efficiency) == 1
                           episode_efficiency = episode_efficiency + repmat(info.efficiency, 1, n_agents);
                       end
                   else
                       % å¦‚æœinfoä¸æ˜¯ç»“æ„ä½“æˆ–æ²¡æœ‰efficiencyå­—æ®µï¼Œä½¿ç”¨é»˜è®¤å€¼
                       episode_efficiency = episode_efficiency + 0.7 * ones(1, n_agents);
                   end
                   
                   state = next_state;
                   
                   if done
                       break;
                   end
               end
               
               % ç´¯ç§¯episodeç»“æœ
               defender_reward_sum = defender_reward_sum + episode_defender_rewards;
               attacker_reward_sum = attacker_reward_sum + episode_attacker_reward;
               detection_rate_sum = detection_rate_sum + episode_detection_rates;
               efficiency_sum = efficiency_sum + episode_efficiency;
           end
           
           % è®¡ç®—å¹³å‡å€¼
           episode_results = struct();
           episode_results.avg_defender_reward = defender_reward_sum / n_episodes;
           episode_results.avg_attacker_reward = attacker_reward_sum / n_episodes;
           episode_results.avg_detection_rate = detection_rate_sum / n_episodes;
           episode_results.avg_efficiency = efficiency_sum / n_episodes;
       end
       
       function updateAgents(defender_agents, attacker_agent, episode_results, config)
    %% æ›´æ–°æ™ºèƒ½ä½“å‚æ•°
    
    n_agents = length(defender_agents);
    
    % æ›´æ–°é˜²å¾¡è€…æ™ºèƒ½ä½“
    for i = 1:n_agents
        if hasMethod(defender_agents{i}, 'updateParameters')
            % ä¸ä¼ é€’å‚æ•°ï¼Œç›´æ¥è°ƒç”¨
            defender_agents{i}.updateParameters();
        end
        
        % æ›´æ–°å­¦ä¹ ç‡ç­‰å‚æ•°
        if hasMethod(defender_agents{i}, 'decay')
            defender_agents{i}.decay();
        end
    end
    
    % æ›´æ–°æ”»å‡»è€…æ™ºèƒ½ä½“
    if hasMethod(attacker_agent, 'updateParameters')
        % ä¸ä¼ é€’å‚æ•°ï¼Œç›´æ¥è°ƒç”¨
        attacker_agent.updateParameters();
    end
    
    if hasMethod(attacker_agent, 'decay')
        attacker_agent.decay();
    end
end
       
       function convergence_info = analyzeConvergence(results)
           %% åˆ†ææ”¶æ•›æ€§
           
           convergence_info = struct();
           
           % åˆ†æé˜²å¾¡è€…å¥–åŠ±æ”¶æ•›
           defender_rewards = results.defender_rewards;
           n_iterations = size(defender_rewards, 1);
           n_agents = size(defender_rewards, 2);
           
           % è®¡ç®—æœ€å20%è¿­ä»£çš„ç¨³å®šæ€§
           stable_window = max(10, floor(n_iterations * 0.2));
           stable_start = n_iterations - stable_window + 1;
           
           convergence_info.defender_convergence = zeros(1, n_agents);
           for i = 1:n_agents
               stable_rewards = defender_rewards(stable_start:end, i);
               convergence_info.defender_convergence(i) = std(stable_rewards) / mean(abs(stable_rewards));
           end
           
           % åˆ†ææ”»å‡»è€…å¥–åŠ±æ”¶æ•›
           attacker_rewards = results.attacker_rewards;
           stable_attacker_rewards = attacker_rewards(stable_start:end);
           convergence_info.attacker_convergence = std(stable_attacker_rewards) / mean(abs(stable_attacker_rewards));
           
           % æ€»ä½“æ”¶æ•›æŒ‡æ ‡
           convergence_info.overall_convergence = mean([convergence_info.defender_convergence, convergence_info.attacker_convergence]);
           
           % æ£€æµ‹æ˜¯å¦æ”¶æ•›ï¼ˆå˜å¼‚ç³»æ•°å°äº0.1è®¤ä¸ºæ”¶æ•›ï¼‰
           convergence_info.is_converged = convergence_info.overall_convergence < 0.1;
           
           % å‡†å¤‡çŠ¶æ€æ–‡æœ¬
           if convergence_info.is_converged
               status_text = '(å·²æ”¶æ•›)';
           else
               status_text = '(æœªæ”¶æ•›)';
           end
           
           fprintf('ğŸ“ˆ æ”¶æ•›åˆ†æ - æ•´ä½“æ”¶æ•›æŒ‡æ ‡: %.4f %s\n', ...
                   convergence_info.overall_convergence, status_text);
       end
   end
end

%% è¾…åŠ©å‡½æ•°
function has_method = hasMethod(obj, method_name)
   %% æ£€æŸ¥å¯¹è±¡æ˜¯å¦æœ‰æŒ‡å®šæ–¹æ³•
   try
       if isobject(obj)
           has_method = any(strcmp(methods(obj), method_name));
       else
           has_method = false;
       end
   catch
       has_method = false;
   end
end