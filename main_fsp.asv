%% main_fsp.m - 修复版FSP-TCS主仿真程序
% =========================================================================
% 描述: 解决Logger静态方法调用问题的主仿真程序
% 版本: v2.1 - 修复Logger调用错误
% =========================================================================

function main_fsp()
    % FSP-TCS主程序入口
    
    clc; clear; close all;
    
    % 添加所有子目录到路径
    addpath(genpath(pwd));
    
    try
        %% === 1. 系统初始化 ===
        fprintf('\n=== FSP-TCS 智能防御系统仿真 v2.1 ===\n');
        fprintf('正在初始化系统...\n\n');
        
        % 加载配置 - 检查ConfigManager是否存在
        if exist('ConfigManager', 'class')
            config = ConfigManager.loadConfig();
            ConfigManager.displayConfigSummary(config);
        else
            % 使用备用配置
            fprintf('ConfigManager不存在，使用备用配置\n');
            config = createBackupConfig();
        end
        
        % 初始化日志系统 - 使用修复后的Logger
        log_file = config.output.log_file;
        Logger.initialize(log_file, 'INFO');
        Logger.info('FSP-TCS仿真开始');
        
        % 设置随机种子
        if isfield(config, 'random_seed')
            rng(config.random_seed);
            Logger.info(sprintf('随机种子设置为: %d', config.random_seed));
        end
        
        %% === 2. 环境和智能体初始化 ===
        fprintf('正在创建环境和智能体...\n');
        
        % 创建环境
        if exist('TCSEnvironment', 'class')
            env = TCSEnvironment(config);
            Logger.info('TCS环境创建完成');
        else
            error('TCSEnvironment类不存在，请检查核心文件');
        end
        
        % 创建智能体
        if exist('AgentFactory', 'class')
            defender_agents = AgentFactory.createDefenderAgents(config, env);
            attacker_agent = AgentFactory.createAttackerAgent(config, env);
            Logger.info(sprintf('智能体创建完成: %d个防御者, 1个攻击者', length(defender_agents)));
        else
            error('AgentFactory类不存在，请检查工具文件');
        end
        
        % 创建性能监控器
        if exist('PerformanceMonitor', 'class')
            monitor = PerformanceMonitor(config.n_iterations, length(defender_agents), config);
            Logger.info('性能监控器初始化完成');
        else
            fprintf('PerformanceMonitor不存在，跳过性能监控\n');
            monitor = [];
        end
        
        %% === 3. FSP仿真主循环 ===
        fprintf('开始FSP仿真训练...\n');
        
        % 初始化结果存储
        results = initializeResults(config, length(defender_agents));
        
        % 仿真主循环
        for iteration = 1:config.n_iterations
            tic;
            
            % 运行一轮episodes
            if exist('FSPSimulator', 'class')
                episode_results = FSPSimulator.runIteration(env, defender_agents, attacker_agent, config, monitor);
            else
                % 使用简化的episode运行
                episode_results = runSimpleEpisodes(env, defender_agents, attacker_agent, config);
            end
            
            % 记录结果
            results = recordIterationResults(results, episode_results, iteration);
            
            % 更新性能监控
            if ~isempty(monitor)
                updatePerformanceMonitor(monitor, iteration, episode_results, config);
            end
            
            % 动态更新学习参数
            if mod(iteration, config.performance.param_update_interval) == 0
                if exist('ConfigManager', 'class')
                    config = ConfigManager.updateLearningParameters(config, iteration);
                else
                    config = updateLearningParametersSimple(config, iteration);
                end
                updateAgentParameters(defender_agents, attacker_agent, config);
            end
            
            % 显示进度
            iteration_time = toc;
            handleIterationOutput(iteration, config, iteration_time, episode_results);
            
            % 保存检查点
            if mod(iteration, config.output.checkpoint_interval) == 0 && config.output.save_checkpoints
                saveCheckpoint(defender_agents, attacker_agent, results, iteration, config);
            end
        end
        
        %% === 4. 结果分析和可视化 ===
        fprintf('\n仿真完成，正在生成分析报告...\n');
        
        % 保存最终结果
        if exist('DataManager', 'class')
            DataManager.saveResults(results, config);
            Logger.info('仿真结果已保存');
        else
            % 使用简单保存方法
            saveResultsSimple(results, config);
        end
        
        % 生成可视化报告
        if config.output.visualization
            if exist('EnhancedVisualization', 'class')
                visualization = EnhancedVisualization(results, config, env);
                visualization.generateCompleteReport();
                Logger.info('可视化报告生成完成');
            else
                fprintf('EnhancedVisualization不存在，跳过可视化\n');
            end
        end
        
        % 生成文本报告
        if config.output.generate_report
            if exist('ReportGenerator', 'class')
                ReportGenerator.generateTextReport(results, config, monitor);
                Logger.info('文本报告生成完成');
            else
                generateSimpleReport(results, config);
            end
        end
        
        %% === 5. 系统清理 ===
        fprintf('\n=== 仿真完成 ===\n');
        printFinalSummary(results, config);
        
        Logger.info('FSP-TCS仿真成功完成');
        Logger.close();
        
    catch ME
        % 错误处理
        fprintf('\n❌ 仿真过程中发生错误:\n');
        fprintf('错误信息: %s\n', ME.message);
        if ~isempty(ME.stack)
            fprintf('错误位置: %s, 行号: %d\n', ME.stack(1).file, ME.stack(1).line);
        end
        
        % 记录错误日志
        if Logger.isInitialized()
            Logger.error(sprintf('仿真出错: %s', ME.message));
            if ~isempty(ME.stack)
                Logger.error(sprintf('错误位置: %s, 行号: %d', ME.stack(1).file, ME.stack(1).line));
            end
            Logger.close();
        end
        
        rethrow(ME);
    end
end

%% === 备用函数 ===

function config = createBackupConfig()
    % 创建备用配置（当ConfigManager不存在时使用）
    
    config = struct();
    
    % 基础系统参数
    config.n_stations = 5;
    config.n_components_per_station = [7, 6, 8, 5, 9];
    config.total_components = sum([7, 6, 8, 5, 9]);
    config.total_resources = 100;
    
    % FSP仿真参数
    config.n_iterations = 500;  % 减少迭代数用于测试
    config.n_episodes_per_iter = 50;
    config.pool_size_limit = 50;
    config.pool_update_interval = 10;
    
    % 强化学习参数
    config.learning_rate = 0.15;
    config.discount_factor = 0.95;
    config.epsilon = 0.4;
    config.epsilon_decay = 0.999;
    config.epsilon_min = 0.05;
    config.temperature = 1.0;
    config.temperature_decay = 0.995;
    
    % 算法配置
    config.algorithms = {'Q-Learning', 'SARSA', 'Double Q-Learning'};
    % 为了兼容性，同时提供 defender_types 字段
    config.defender_types = config.algorithms;
    
    % 攻击系统配置
    config.attack_types = {'wireless_spoofing', 'dos_attack', 'semantic_attack'};
    config.attack_severity = [0.3, 0.5, 0.7];
    config.attack_detection_difficulty = [0.4, 0.3, 0.7];
    
    % 资源系统配置
    config.resource_types = {'computation', 'bandwidth', 'sensors', 'scanning_freq', 'inspection_depth'};
    config.resource_effectiveness = [0.7, 0.6, 0.8, 0.5, 0.9];
    
    % RADI配置
    config.radi = struct();
    config.radi.optimal_allocation = [0.2, 0.2, 0.2, 0.2, 0.2];
    config.radi.weight_computation = 0.3;
    config.radi.weight_bandwidth = 0.2;
    config.radi.weight_sensors = 0.2;
    config.radi.weight_scanning = 0.15;
    config.radi.weight_inspection = 0.15;
    config.radi.threshold_excellent = 0.1;
    config.radi.threshold_good = 0.2;
    config.radi.threshold_acceptable = 0.3;
    
    % 奖励函数配置
    config.reward = struct();
    config.reward.w_radi = 0.4;
    config.reward.w_efficiency = 0.3;
    config.reward.w_balance = 0.3;
    
    % 性能监控配置
    config.performance = struct();
    config.performance.display_interval = 50;
    config.performance.save_interval = 100;
    config.performance.param_update_interval = 50;
    config.performance.convergence_threshold = 0.01;
    
    % 输出配置
    config.output = struct();
    config.output.visualization = true;
    config.output.generate_report = true;
    config.output.save_models = false;
    config.output.save_checkpoints = false;
    config.output.checkpoint_interval = 500;
    
    % 文件路径
    timestamp = datestr(now, 'yyyymmdd_HHMMSS');
    config.output.log_file = sprintf('logs/simulation_%s.log', timestamp);
    config.output.results_dir = 'results';
    config.output.report_dir = 'reports';
    
    % 随机种子
    config.random_seed = 42;
    
    fprintf('✓ 备用配置创建完成\n');
end

function episode_results = runSimpleEpisodes(env, defender_agents, attacker_agent, config)
    % 简化的episode运行（当FSPSimulator不存在时使用）
    
    n_agents = length(defender_agents);
    n_episodes = config.n_episodes_per_iter;
    
    % 初始化结果结构
    episode_results = struct();
    episode_results.avg_radi = zeros(1, n_agents);
    episode_results.avg_efficiency = zeros(1, n_agents);
    episode_results.avg_balance = zeros(1, n_agents);
    episode_results.avg_defender_reward = zeros(1, n_agents);
    episode_results.avg_attacker_reward = 0;
    episode_results.attack_info = num2cell(rand(n_episodes, 1) < 0.3); % 模拟攻击成功率
    
    % 运行episodes
    radi_sum = zeros(1, n_agents);
    efficiency_sum = zeros(1, n_agents);
    balance_sum = zeros(1, n_agents);
    defender_reward_sum = zeros(1, n_agents);
    attacker_reward_sum = 0;
    
    for ep = 1:n_episodes
        % 重置环境
        state = env.reset();
        
        % 每个防御者选择动作
        for agent_idx = 1:n_agents
            defender_action = defender_agents{agent_idx}.selectAction(state);
            attacker_action = attacker_agent.selectAction(state);
            
            % 执行环境步骤
            [next_state, reward, ~, info] = env.step(defender_action, attacker_action);
            
            % 计算RADI和其他指标
            if isfield(info, 'resource_allocation')
                allocation = info.resource_allocation;
            else
                allocation = ones(1, 5) * 20; % 默认分配
            end
            
            radi = calculateRADI(allocation, config.radi.optimal_allocation, config.radi);
            efficiency = mean(allocation) / config.total_resources;
            balance = 1 - std(allocation) / mean(allocation);
            
            % 累加结果
            radi_sum(agent_idx) = radi_sum(agent_idx) + radi;
            efficiency_sum(agent_idx) = efficiency_sum(agent_idx) + efficiency;
            balance_sum(agent_idx) = balance_sum(agent_idx) + balance;
            defender_reward_sum(agent_idx) = defender_reward_sum(agent_idx) + reward;
            
            % 更新智能体
            defender_agents{agent_idx}.update(state, defender_action, reward, next_state, []);
        end
        
        % 更新攻击者
        attacker_reward = -mean(defender_reward_sum) / n_agents; % 简化的攻击者奖励
        attacker_reward_sum = attacker_reward_sum + attacker_reward;
        attacker_agent.update(state, attacker_action, attacker_reward, next_state, []);
    end
    
    % 计算平均值
    episode_results.avg_radi = radi_sum / n_episodes;
    episode_results.avg_efficiency = efficiency_sum / n_episodes;
        % 计算平均值
    episode_results.avg_radi = radi_sum / n_episodes;
    episode_results.avg_efficiency = efficiency_sum / n_episodes;
    episode_results.avg_balance = balance_sum / n_episodes;
    episode_results.avg_defender_reward = defender_reward_sum / n_episodes;
    episode_results.avg_attacker_reward = attacker_reward_sum / n_episodes;
    
    % 其他结果字段
    episode_results.avg_resource_allocation = repmat([20, 20, 20, 20, 20], n_agents, 1);
    episode_results.attacker_strategy = ones(1, config.n_stations) / config.n_stations;
    episode_results.defender_strategies = cell(n_agents, 1);
    for i = 1:n_agents
        episode_results.defender_strategies{i} = ones(1, config.n_stations) / config.n_stations;
    end
end

function config = updateLearningParametersSimple(config, iteration)
    % 简化的学习参数更新
    
    % 更新探索率
    config.epsilon = max(config.epsilon_min, config.epsilon * config.epsilon_decay);
    
    % 更新学习率
    if iteration > 100
        decay_factor = 1 / (1 + 0.001 * (iteration - 100));
        config.learning_rate = max(0.01, config.learning_rate * decay_factor);
    end
    
    % 更新温度参数
    if isfield(config, 'temperature')
        config.temperature = max(0.1, config.temperature * config.temperature_decay);
    end
end

function updateAgentParameters(defender_agents, attacker_agent, config)
    % 更新智能体学习参数
    
    % 更新防御者智能体参数
    for i = 1:length(defender_agents)
        if isprop(defender_agents{i}, 'learning_rate') || isfield(defender_agents{i}, 'learning_rate')
            defender_agents{i}.learning_rate = config.learning_rate;
        end
        if isprop(defender_agents{i}, 'epsilon') || isfield(defender_agents{i}, 'epsilon')
            defender_agents{i}.epsilon = config.epsilon;
        end
        if isprop(defender_agents{i}, 'temperature') || isfield(defender_agents{i}, 'temperature')
            if isfield(config, 'temperature')
                defender_agents{i}.temperature = config.temperature;
            end
        end
    end
    
    % 更新攻击者智能体参数
    if isprop(attacker_agent, 'learning_rate') || isfield(attacker_agent, 'learning_rate')
        attacker_agent.learning_rate = config.learning_rate;
    end
    if isprop(attacker_agent, 'epsilon') || isfield(attacker_agent, 'epsilon')
        attacker_agent.epsilon = config.epsilon;
    end
    if isprop(attacker_agent, 'temperature') || isfield(attacker_agent, 'temperature')
        if isfield(config, 'temperature')
            attacker_agent.temperature = config.temperature;
        end
    end
end

function results = initializeResults(config, n_agents)
    % 初始化结果存储结构
    
    results = struct();
    results.config = config;
    results.n_iterations = config.n_iterations;
    results.n_agents = n_agents;
    results.timestamp = datestr(now);
    
    % 性能指标历史
    results.radi_history = zeros(config.n_iterations, n_agents);
    results.success_rate_history = zeros(config.n_iterations, 1);
    results.detection_rate_history = zeros(config.n_iterations, 1);
    results.resource_efficiency = zeros(config.n_iterations, n_agents);
    results.allocation_balance = zeros(config.n_iterations, n_agents);
    
    % 策略历史
    results.attacker_strategy_history = zeros(config.n_iterations, config.n_stations);
    results.defender_strategy_history = cell(n_agents, 1);
    for i = 1:n_agents
        results.defender_strategy_history{i} = zeros(config.n_iterations, config.n_stations);
    end
    
    % 奖励历史
    results.defender_rewards = zeros(config.n_iterations, n_agents);
    results.attacker_rewards = zeros(config.n_iterations, 1);
    
    % 学习参数历史
    results.epsilon_history = zeros(config.n_iterations, 1);
    results.learning_rate_history = zeros(config.n_iterations, 1);
    results.temperature_history = zeros(config.n_iterations, 1);
end

function results = recordIterationResults(results, episode_results, iteration)
    % 记录单次迭代的结果
    
    % 性能指标
    results.radi_history(iteration, :) = episode_results.avg_radi;
    results.success_rate_history(iteration) = mean([episode_results.attack_info{:}]);
    results.resource_efficiency(iteration, :) = episode_results.avg_efficiency;
    results.allocation_balance(iteration, :) = episode_results.avg_balance;
    
    % 奖励信息
    results.defender_rewards(iteration, :) = episode_results.avg_defender_reward;
    results.attacker_rewards(iteration) = episode_results.avg_attacker_reward;
    
    % 策略信息
    if isfield(episode_results, 'attacker_strategy')
        results.attacker_strategy_history(iteration, :) = episode_results.attacker_strategy;
    end
    
    if isfield(episode_results, 'defender_strategies')
        for i = 1:length(episode_results.defender_strategies)
            results.defender_strategy_history{i}(iteration, :) = episode_results.defender_strategies{i};
        end
    end
end

function updatePerformanceMonitor(monitor, iteration, episode_results, config)
    % 更新性能监控器
    
    % 构造监控指标
    metrics = struct();
    metrics.resource_allocation = mean(episode_results.avg_resource_allocation, 1);
    metrics.resource_efficiency = mean(episode_results.avg_efficiency);
    metrics.allocation_balance = mean(episode_results.avg_balance);
    metrics.detection_rate = 1 - mean([episode_results.attack_info{:}]); % 检测率 = 1 - 攻击成功率
    
    % 更新监控器
    monitor.updateMetrics(iteration, metrics);
    
    % 实时状态显示
    if mod(iteration, config.performance.display_interval) == 0
        monitor.displayRealTimeStatus(iteration);
    end
end

function handleIterationOutput(iteration, config, iteration_time, episode_results)
    % 处理迭代输出和进度显示
    
    % 显示进度信息
    if mod(iteration, config.performance.display_interval) == 0
        avg_radi = mean(episode_results.avg_radi);
        avg_success_rate = mean([episode_results.attack_info{:}]);
        avg_efficiency = mean(episode_results.avg_efficiency);
        
        fprintf('Iteration %d/%d: RADI=%.3f, Success=%.3f, Efficiency=%.3f, Time=%.2fs\n', ...
                iteration, config.n_iterations, avg_radi, avg_success_rate, avg_efficiency, iteration_time);
        
        Logger.info(sprintf('迭代 %d 完成，用时 %.2f秒', iteration, iteration_time));
    end
    
    % 保存中间结果
    if mod(iteration, config.performance.save_interval) == 0
        fprintf('保存中间结果...\n');
        % 这里可以保存中间结果
    end
end

function saveCheckpoint(defender_agents, attacker_agent, results, iteration, config)
    % 保存训练检查点
    
    checkpoint_dir = config.output.checkpoints_dir;
    if ~exist(checkpoint_dir, 'dir')
        mkdir(checkpoint_dir);
    end
    
    checkpoint_file = fullfile(checkpoint_dir, sprintf('checkpoint_iter_%d.mat', iteration));
    
    try
        % 保存智能体状态
        agents_state = struct();
        agents_state.defender_agents = defender_agents;
        agents_state.attacker_agent = attacker_agent;
        agents_state.iteration = iteration;
        agents_state.config = config;
        agents_state.results = results;
        
        save(checkpoint_file, 'agents_state');
        Logger.info(sprintf('检查点已保存: %s', checkpoint_file));
        
    catch ME
        warning('保存检查点失败: %s', ME.message);
        Logger.warning(sprintf('检查点保存失败: %s', ME.message));
    end
end

function saveResultsSimple(results, config)
    % 简单的结果保存方法
    
    results_dir = config.output.results_dir;
    if ~exist(results_dir, 'dir')
        mkdir(results_dir);
    end
    
    timestamp = datestr(now, 'yyyymmdd_HHMMSS');
    results_file = fullfile(results_dir, sprintf('fsp_results_%s.mat', timestamp));
    
    try
        save(results_file, 'results', 'config');
        fprintf('✓ 结果已保存: %s\n', results_file);
        Logger.info(sprintf('仿真结果已保存: %s', results_file));
    catch ME
        warning('保存结果失败: %s', ME.message);
        Logger.warning(sprintf('结果保存失败: %s', ME.message));
    end
end

function generateSimpleReport(results, config)
    % 生成简单的文本报告
    
    report_dir = config.output.report_dir;
    if ~exist(report_dir, 'dir')
        mkdir(report_dir);
    end
    
    timestamp = datestr(now, 'yyyymmdd_HHMMSS');
    report_file = fullfile(report_dir, sprintf('simple_report_%s.txt', timestamp));
    
    try
        fid = fopen(report_file, 'w');
        
        fprintf(fid, 'FSP-TCS 仿真报告\n');
        fprintf(fid, '==================\n');
        fprintf(fid, '生成时间: %s\n\n', datestr(now));
        
        fprintf(fid, '配置信息:\n');
        fprintf(fid, '  迭代次数: %d\n', config.n_iterations);
        fprintf(fid, '  智能体数量: %d\n', results.n_agents);
        fprintf(fid, '  算法: %s\n', strjoin(config.algorithms, ', '));
        
        fprintf(fid, '\n性能结果:\n');
        final_radi = mean(results.radi_history(end, :));
        fprintf(fid, '  最终RADI: %.3f\n', final_radi);
        
        final_success_rate = results.success_rate_history(end);
        fprintf(fid, '  最终攻击成功率: %.3f\n', final_success_rate);
        
        fclose(fid);
        fprintf('✓ 简单报告已生成: %s\n', report_file);
        Logger.info(sprintf('简单报告已生成: %s', report_file));
        
    catch ME
        warning('生成报告失败: %s', ME.message);
        Logger.warning(sprintf('报告生成失败: %s', ME.message));
    end
end

function printFinalSummary(results, config)
    % 打印最终结果摘要
    
    fprintf('\n=== 仿真结果摘要 ===\n');
    
    % 性能指标
    final_radi = mean(results.radi_history(end-min(99,end-1):end, :), 'all');
    initial_radi = mean(results.radi_history(1:min(100,end), :), 'all');
    radi_improvement = initial_radi - final_radi;
    
    final_success_rate = mean(results.success_rate_history(end-min(99,end-1):end));
    initial_success_rate = mean(results.success_rate_history(1:min(100,end)));
    success_improvement = final_success_rate - initial_success_rate;
    
    final_efficiency = mean(results.resource_efficiency(end-min(99,end-1):end, :), 'all');
    
    fprintf('性能改善:\n');
    fprintf('  RADI: %.3f → %.3f (改善: %.3f)\n', initial_radi, final_radi, radi_improvement);
    fprintf('  攻击成功率: %.3f → %.3f (变化: %+.3f)\n', initial_success_rate, final_success_rate, success_improvement);
    fprintf('  资源效率: %.3f\n', final_efficiency);
    
    % 训练统计
    fprintf('\n训练统计:\n');
    fprintf('  总迭代数: %d\n', config.n_iterations);
    fprintf('  每轮Episodes: %d\n', config.n_episodes_per_iter);
    fprintf('  智能体数量: %d\n', size(results.radi_history, 2));
    fprintf('  最终探索率: %.3f\n', config.epsilon);
    fprintf('  最终学习率: %.3f\n', config.learning_rate);
    
    % 算法比较
    if size(results.radi_history, 2) > 1
        fprintf('\n算法性能对比 (最终RADI):\n');
        for i = 1:length(config.algorithms)
            final_radi_agent = mean(results.radi_history(end-min(99,end-1):end, i));
            fprintf('  %s: %.3f\n', config.algorithms{i}, final_radi_agent);
        end
    end
    
    fprintf('==================\n');
end

%% === 其他功能函数 ===

function enhanced_main_fsp()
    % 运行多智能体版本的仿真
    fprintf('多智能体仿真功能正在开发中...\n');
    fprintf('请使用标准仿真模式\n');
end

function quick_test_mode()
    % 快速测试模式
    fprintf('\n=== 快速测试模式 ===\n');
    
    try
        % 使用测试配置
        if exist('ConfigManager', 'class')
            config = ConfigManager.getTestConfig();
        else
            config = createBackupConfig();
            config.n_iterations = 10;  % 很少的迭代数
            config.n_episodes_per_iter = 5;
        end
        
        fprintf('测试配置: %d次迭代, 每轮%d个episodes\n', ...
                config.n_iterations, config.n_episodes_per_iter);
        
        % 运行快速测试
        main_fsp_simulation_optimized();
        
    catch ME
        fprintf('❌ 快速测试失败: %s\n', ME.message);
        if ~isempty(ME.stack)
            fprintf('错误位置: %s, 行号: %d\n', ME.stack(1).file, ME.stack(1).line);
        end
    end
end

function validateAllConfigs()
    % 验证所有预定义配置的有效性
    
    fprintf('\n=== 配置验证测试 ===\n');
    
    % 测试ConfigManager配置
    if exist('ConfigManager', 'class')
        configs = {
            ConfigManager.getDefaultConfig(), '默认配置';
            ConfigManager.getOptimizedConfig(), '优化配置';
            ConfigManager.getTestConfig(), '测试配置'
        };
        
        for i = 1:size(configs, 1)
            config = configs{i, 1};
            name = configs{i, 2};
            
            fprintf('\n验证 %s...\n', name);
            try
                ConfigManager.validateConfig(config);
                fprintf('✓ %s 验证通过\n', name);
            catch ME
                fprintf('❌ %s 验证失败: %s\n', name, ME.message);
            end
        end
    else
        fprintf('ConfigManager不存在，跳过配置验证\n');
    end
    
    % 测试AgentFactory配置验证
    if exist('AgentFactory', 'class')
        fprintf('\n验证智能体工厂...\n');
        try
            config = createBackupConfig();
            AgentFactory.validateConfiguration(config);
            fprintf('✓ AgentFactory 验证通过\n');
        catch ME
            fprintf('❌ AgentFactory 验证失败: %s\n', ME.message);
        end
    else
        fprintf('AgentFactory不存在，跳过智能体验证\n');
    end
    
    % 测试Logger
    fprintf('\n验证Logger系统...\n');
    try
        Logger.initialize('logs/test_log.log', 'INFO');
        Logger.info('测试日志消息');
        Logger.warning('测试警告消息');
        Logger.error('测试错误消息');
        Logger.close();
        fprintf('✓ Logger 验证通过\n');
    catch ME
        fprintf('❌ Logger 验证失败: %s\n', ME.message);
    end
    
    fprintf('\n配置验证完成。\n');
end

%% === 全局函数（确保存在） ===

function radi = calculateRADI(resource_allocation, optimal_allocation, radi_config)
    % 计算RADI指标的全局函数
    % 输入:
    %   resource_allocation - 当前资源分配向量
    %   optimal_allocation - 最优资源分配向量
    %   radi_config - RADI配置结构体
    % 输出:
    %   radi - RADI指标值
    
    if nargin < 3 || ~isstruct(radi_config)
        % 使用默认权重
        weights = ones(1, length(resource_allocation)) / length(resource_allocation);
    else
        % 从配置中获取权重
        weights = [
            radi_config.weight_computation;
            radi_config.weight_bandwidth;
            radi_config.weight_sensors;
            radi_config.weight_scanning;
            radi_config.weight_inspection
        ];
        
        % 确保权重长度正确
        if length(weights) ~= length(resource_allocation)
            weights = ones(1, length(resource_allocation)) / length(resource_allocation);
        else
            weights = weights' / sum(weights); % 转置并归一化
        end
    end
    
    % 确保向量长度一致
    min_len = min([length(resource_allocation), length(optimal_allocation), length(weights)]);
    resource_allocation = resource_allocation(1:min_len);
    optimal_allocation = optimal_allocation(1:min_len);
    weights = weights(1:min_len);
    
    % 计算归一化的资源分配
    if sum(resource_allocation) > 0
        norm_allocation = resource_allocation / sum(resource_allocation);
    else
        norm_allocation = ones(size(resource_allocation)) / length(resource_allocation);
    end
    
    if sum(optimal_allocation) > 0
        norm_optimal = optimal_allocation / sum(optimal_allocation);
    else
        norm_optimal = ones(size(optimal_allocation)) / length(optimal_allocation);
    end
    
    % 计算加权偏差
    deviation = abs(norm_allocation - norm_optimal);
    radi = sum(weights .* deviation);
    
    % 确保RADI值在合理范围内
    radi = max(0, min(radi, 2)); % RADI值通常在[0,2]范围内
end

